name: CI/CD Pipeline

on:
  push:
    branches: [ main, development ]
  pull_request:
    branches: [ main, development ]
  workflow_dispatch:

env:
  NODE_VERSION_MATRIX: '[18, 20, 22]'

jobs:
  # Job 1: Setup and Basic Dependency Install
  setup:
    name: Setup Dependencies
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            **/node_modules
          key: ${{ runner.os }}-npm-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-

      - name: Install dependencies
        run: |
          npm ci
          cd frontend && npm ci
          cd ../backend && npm ci
          cd ../ai-service && npm ci

      - name: Verify installations
        run: |
          echo "✅ All dependencies installed successfully"
          node --version
          npm --version

  # Job 2: Matrix Testing with Multiple Node.js Versions
  test-matrix:
    name: Test Matrix (Node ${{ matrix.node-version }})
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: setup
    
    strategy:
      matrix:
        node-version: [18, 20, 22]
        service: [frontend, backend, ai-service]
      fail-fast: false

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            **/node_modules
          key: ${{ runner.os }}-node${{ matrix.node-version }}-${{ matrix.service }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node${{ matrix.node-version }}-${{ matrix.service }}-

      - name: Install dependencies
        working-directory: ./${{ matrix.service }}
        run: npm ci

      - name: Run tests with coverage
        working-directory: ./${{ matrix.service }}
        env:
          SKIP_DOCKER_TESTS: true
        run: npm run test:coverage

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./${{ matrix.service }}/coverage/lcov.info
          flags: ${{ matrix.service }}-node${{ matrix.node-version }}
          name: ${{ matrix.service }}-coverage-node${{ matrix.node-version }}
          fail_ci_if_error: false

      - name: Upload test artifacts
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.service }}-node${{ matrix.node-version }}
          path: |
            ./${{ matrix.service }}/coverage/
            ./${{ matrix.service }}/test-results.xml
          retention-days: 7

  # Job 3: End-to-End Testing
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [setup, test-matrix]
    
    services:
      mongo:
        image: mongo:4.4
        ports:
          - 27017:27017
        env:
          MONGO_INITDB_DATABASE: brainbytes
        options: >-
          --health-cmd mongosh
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            **/node_modules
          key: ${{ runner.os }}-e2e-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-e2e-

      - name: Install dependencies
        run: |
          npm ci
          cd frontend && npm ci
          cd ../backend && npm ci
          cd ../ai-service && npm ci

      - name: Install Playwright
        working-directory: ./e2e-tests
        run: |
          npm ci
          npx playwright install --with-deps

      - name: Start services
        run: |
          # Start backend
          cd backend && npm start &
          BACKEND_PID=$!
          echo "BACKEND_PID=$BACKEND_PID" >> $GITHUB_ENV
          
          # Start AI service
          cd ../ai-service && npm start &
          AI_SERVICE_PID=$!
          echo "AI_SERVICE_PID=$AI_SERVICE_PID" >> $GITHUB_ENV
          
          # Start frontend
          cd ../frontend && npm run build && npm start &
          FRONTEND_PID=$!
          echo "FRONTEND_PID=$FRONTEND_PID" >> $GITHUB_ENV
          
          # Wait for services to be ready
          sleep 30

      - name: Run E2E tests
        working-directory: ./e2e-tests
        run: npx playwright test

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: |
            ./e2e-tests/test-results/
            ./e2e-tests/playwright-report/
          retention-days: 7

      - name: Cleanup services
        if: always()
        run: |
          kill $BACKEND_PID $AI_SERVICE_PID $FRONTEND_PID 2>/dev/null || true

  # Job 4: Performance Testing
  performance-test:
    name: Performance Testing
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [test-matrix]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm install -g artillery
          cd frontend && npm ci
          cd ../backend && npm ci
          cd ../ai-service && npm ci

      - name: Start services for performance testing
        run: |
          # Start backend
          cd backend && npm start &
          BACKEND_PID=$!
          echo "BACKEND_PID=$BACKEND_PID" >> $GITHUB_ENV
          
          # Start AI service
          cd ../ai-service && npm start &
          AI_SERVICE_PID=$!
          echo "AI_SERVICE_PID=$AI_SERVICE_PID" >> $GITHUB_ENV
          
          # Start frontend
          cd ../frontend && npm run build && npm start &
          FRONTEND_PID=$!
          echo "FRONTEND_PID=$FRONTEND_PID" >> $GITHUB_ENV
          
          # Wait for services to be ready
          sleep 30

      - name: Run performance tests
        run: |
          # Create basic artillery config
          cat > performance-test.yml << EOF
          config:
            target: 'http://localhost:3000'
            phases:
              - duration: 60
                arrivalRate: 10
          scenarios:
            - name: "API Load Test"
              requests:
                - get:
                    url: "/health"
          EOF
          
          artillery run performance-test.yml --output performance-report.json

      - name: Generate performance report
        run: |
          artillery report performance-report.json --output performance-report.html

      - name: Upload performance artifacts
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: |
            performance-report.json
            performance-report.html
          retention-days: 7

      - name: Cleanup services
        if: always()
        run: |
          kill $BACKEND_PID $AI_SERVICE_PID $FRONTEND_PID 2>/dev/null || true

  # Job 5: Test Summary
  test-summary:
    name: Test Summary Report
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [test-matrix, e2e-tests, performance-test]
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4

      - name: Generate test summary
        run: |
          echo "# Test Summary Report" > test-summary.md
          echo "Generated on: $(date)" >> test-summary.md
          echo "" >> test-summary.md
          
          # Check if test artifacts exist and summarize
          if [ -d "test-results-frontend-node20" ]; then
            echo "✅ Frontend tests completed" >> test-summary.md
          else
            echo "❌ Frontend tests failed" >> test-summary.md
          fi
          
          if [ -d "test-results-backend-node20" ]; then
            echo "✅ Backend tests completed" >> test-summary.md
          else
            echo "❌ Backend tests failed" >> test-summary.md
          fi
          
          if [ -d "e2e-test-results" ]; then
            echo "✅ E2E tests completed" >> test-summary.md
          else
            echo "❌ E2E tests failed" >> test-summary.md
          fi
          
          if [ -d "performance-results" ]; then
            echo "✅ Performance tests completed" >> test-summary.md
          else
            echo "❌ Performance tests failed or skipped" >> test-summary.md
          fi

      - name: Upload test summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test-summary.md
          retention-days: 30

  # Job 6: Notification
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [test-summary]
    if: always()
    
    steps:
      - name: Determine workflow status
        id: status
        run: |
          if [[ "${{ needs.test-summary.result }}" == "success" ]]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "emoji=✅" >> $GITHUB_OUTPUT
            echo "message=All CI/CD checks passed successfully!" >> $GITHUB_OUTPUT
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "emoji=❌" >> $GITHUB_OUTPUT
            echo "message=Some CI/CD checks failed. Please review the results." >> $GITHUB_OUTPUT
          fi

      - name: Create workflow summary
        run: |
          echo "## ${{ steps.status.outputs.emoji }} CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ steps.status.outputs.message }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Job Results:" >> $GITHUB_STEP_SUMMARY
          echo "- **Setup:** ${{ needs.setup.result || 'N/A' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Matrix:** ${{ needs.test-matrix.result || 'N/A' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **E2E Tests:** ${{ needs.e2e-tests.result || 'N/A' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Performance Tests:** ${{ needs.performance-test.result || 'N/A' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> 💡 **Note:** Docker builds and deployments are handled by the separate [Deploy to Environments](../actions/workflows/deploy.yml) workflow."

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && comment.body.includes('CI/CD Pipeline Summary')
            );
            
            const body = `## ${{ steps.status.outputs.emoji }} CI/CD Pipeline Summary
            
            **Status:** ${{ steps.status.outputs.message }}
            **Branch:** ${{ github.ref_name }}
            **Commit:** ${{ github.sha }}
            
            ### Job Results:
            - **Setup:** ${{ needs.setup.result || 'N/A' }}
            - **Test Matrix:** ${{ needs.test-matrix.result || 'N/A' }}  
            - **E2E Tests:** ${{ needs.e2e-tests.result || 'N/A' }}
            - **Performance Tests:** ${{ needs.performance-test.result || 'N/A' }}
            
            > 💡 **Note:** Code quality checks are handled by [Code Quality & Security](../actions/workflows/code-quality.yml) and Docker builds/deployments by [Deploy to Environments](../actions/workflows/deploy.yml).`;
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }